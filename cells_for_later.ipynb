{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849f600d-4d90-47c7-9fbc-d2cb92c048bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## General, \"all frames\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bedf4-2d4d-4443-8bd9-cfe3f8b5e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JesterVideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A Dataset class for the 20BN-JESTER dataset structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_root, annotation_file, transform=None, text_label_dict=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_root (str): Root directory containing the numbered folders (e.g., \"3_assign/...\").\n",
    "            annotation_file (str): Path to the CSV file (e.g., \"jester-v1-train.csv\").\n",
    "                                   Format expected: \"video_id;label_name\"\n",
    "            transform (callable, optional): Transform to apply to the *sequence* of images.\n",
    "            text_label_dict (dict, optional): Dictionary mapping class names to integers. \n",
    "                                              If None, it is built automatically.\n",
    "        \"\"\"\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 1. Read the CSV file that maps Folder IDs to Labels\n",
    "        # Jester CSVs usually have no header and use semicolon delimiter\n",
    "        df = pd.read_csv(annotation_file, sep=';', header=None, names=['video_id', 'label'])\n",
    "        \n",
    "        # Convert video_ids to string to match folder names safely\n",
    "        self.video_ids = df['video_id'].astype(str).tolist()\n",
    "        raw_labels = df['label'].tolist()\n",
    "\n",
    "        # 2. Handle Labels (String -> Integer mapping)\n",
    "        # If a dictionary is provided (e.g., from the training set), use it. \n",
    "        # Otherwise create one.\n",
    "        if text_label_dict is not None:\n",
    "            self.class_to_idx = text_label_dict\n",
    "        else:\n",
    "            unique_labels = sorted(list(set(raw_labels)))\n",
    "            self.class_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "            \n",
    "        self.labels = [self.class_to_idx[l] for l in raw_labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            video_frames (list or Tensor): A list/stack of transformed images.\n",
    "            label (int): The class index.\n",
    "        \"\"\"\n",
    "        video_id = self.video_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Path to the specific video folder (e.g., root/147000)\n",
    "        video_dir = os.path.join(self.data_root, video_id)\n",
    "        \n",
    "        # 3. Load Images\n",
    "        # We must sort the images so the video plays in order (00001.jpg, 00002.jpg...)\n",
    "        try:\n",
    "            frame_names = sorted([x for x in os.listdir(video_dir) if x.endswith('.jpg')])\n",
    "        except FileNotFoundError:\n",
    "            # Fallback if a folder in the CSV is missing from the directory\n",
    "            print(f\"Warning: Missing folder {video_dir}\")\n",
    "            return torch.zeros(1), label \n",
    "\n",
    "        frames = []\n",
    "        for frame_name in frame_names:\n",
    "            img_path = os.path.join(video_dir, frame_name)\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            frames.append(image)\n",
    "\n",
    "        # 4. Apply Transforms\n",
    "        # Note: Standard transforms work on single images. \n",
    "        # For videos, you usually loop through the list and apply the transform to each frame.\n",
    "        if self.transform:\n",
    "            # Assuming transform expects a single PIL image and returns a Tensor\n",
    "            frames = [self.transform(img) for img in frames]\n",
    "            \n",
    "            # Stack them into a tensor of shape (Sequence_Length, Channels, Height, Width)\n",
    "            # e.g., (32, 3, 224, 224)\n",
    "            frames = torch.stack(frames) \n",
    "        \n",
    "        return frames, label\n",
    "\n",
    "    def get_class_mapping(self):\n",
    "        \"\"\"Returns the dictionary mapping label names to integers.\"\"\"\n",
    "        return self.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2933661-889e-4670-a9df-2e2b7905be1f",
   "metadata": {},
   "source": [
    "## 3D stacked class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdb562-4472-4d38-ae6e-df947cedc858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Jester3DStackedDataset(Dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-tester",
   "language": "python",
   "name": "torch-tester"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
