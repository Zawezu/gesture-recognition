{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e0178a-4273-424e-943b-249fbc31b639",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initial Data Integrity check (can be skipped after being ran once)"
   ]
  },
  {
   "cell_type": "code",
   "id": "51286c5d-c749-47ab-85a1-ad55f9a1b5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T11:08:21.223012Z",
     "start_time": "2025-11-30T11:08:20.222408Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "use_small_train = True\n",
    "\n",
    "personal_path = \"/vol/home/s4316061/CV_assignments/3_assign/\"\n",
    "if use_small_train:\n",
    "    train_path_of_choice = \"jester-v1-small-train.csv\"\n",
    "    data_download_path = 'downloaded_data_small/small-20bn-jester-v1/'\n",
    "else:\n",
    "    train_path_of_choice = \"jester-v1-train.csv\"\n",
    "    data_download_path = 'something_else_entirely'\n",
    "    \n",
    "# valid is the same, regardless of the train set\n",
    "validation_path = \"jester-v1-validation.csv\"\n",
    "\n",
    "train = pd.read_csv(personal_path + train_path_of_choice, sep=';', header=None, names=['id', 'gesture'])\n",
    "valid = pd.read_csv(personal_path + validation_path, sep=';', header=None, names=['id', 'gesture'])\n",
    "\n",
    "# get all the directory names of the subdirectories available (data is in 'big_dir/many_small_dirs/actual_images' format)\n",
    "root = personal_path + data_download_path\n",
    "subdir_set = {entry.name for entry in os.scandir(root) if entry.is_dir()}\n",
    "\n",
    "print(train.shape[0] + valid.shape[0])  # sanity check These numbers should match, withing a reasonable degree\n",
    "print(len(subdir_set)) \n",
    "\n",
    "# concatenating the DataFrames for easy querying\n",
    "train_and_valid = pd.concat([train, valid], axis=0, ignore_index=True)\n",
    "\n",
    "available_ids = set(train_and_valid['id'].astype(str).unique())\n",
    "\n",
    "missing_val = available_ids - subdir_set\n",
    "extra_val = subdir_set - available_ids\n",
    "\n",
    "print(f\"Values (ids) available in csv, but not downloaded: {missing_val} (should be none)\")\n",
    "print(f\"Extra values in downloaded, but not in csv: {extra_val}\")\n",
    "\n",
    "# making sure the numbers are the same (possibly redundant, but I like to check sometimes)\n",
    "print(\"Manual checks\")\n",
    "val = '74335'\n",
    "print(val in subdir_set)\n",
    "print(val in available_ids)\n",
    "\n",
    "train_ids = set(train['id'].astype(str).unique())\n",
    "val_ids = set(valid['id'].astype(str).unique())"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/vol/home/s4316061/CV_assignments/3_assign/jester-v1-small-train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# valid is the same, regardless of the train set\u001B[39;00m\n\u001B[32m     15\u001B[39m validation_path = \u001B[33m\"\u001B[39m\u001B[33mjester-v1-validation.csv\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m train = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpersonal_path\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_path_of_choice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m;\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mid\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mgesture\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m valid = pd.read_csv(personal_path + validation_path, sep=\u001B[33m'\u001B[39m\u001B[33m;\u001B[39m\u001B[33m'\u001B[39m, header=\u001B[38;5;28;01mNone\u001B[39;00m, names=[\u001B[33m'\u001B[39m\u001B[33mid\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mgesture\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# get all the directory names of the subdirectories available (data is in 'big_dir/many_small_dirs/actual_images' format)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\computer_vision\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '/vol/home/s4316061/CV_assignments/3_assign/jester-v1-small-train.csv'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6d7fb887-c35d-44ac-bba4-6dca0985a664",
   "metadata": {},
   "source": [
    "## Command cell (Linux ONLY): removes the extra video directory found, as it does not have a correspondent in the csv files\n",
    "And I won't go searching for 1 item in the 118K row csv file"
   ]
  },
  {
   "cell_type": "code",
   "id": "4731974b-047c-466a-976e-1c842f913f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:42:09.955671300Z",
     "start_time": "2025-11-29T19:37:36.225378Z"
    }
   },
   "source": [
    "# !rm -r ~/CV_assignments/3_assign/downloaded_data_small/small-20bn-jester-v1/74335"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7a38e2de-0b5f-498a-8e8a-3f80b2973ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:42:09.955671300Z",
     "start_time": "2025-11-29T19:37:36.661944Z"
    }
   },
   "source": [
    "train_and_valid = train_and_valid[~train_and_valid['id'].astype(str).isin(extra_val)]\n",
    "\n",
    "# observing output shape, just to assess the overall size of the data available\n",
    "print(f\"new shape: {train_and_valid.shape}\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m train_and_valid = \u001B[43mtrain_and_valid\u001B[49m[~train_and_valid[\u001B[33m'\u001B[39m\u001B[33mid\u001B[39m\u001B[33m'\u001B[39m].astype(\u001B[38;5;28mstr\u001B[39m).isin(extra_val)]\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# observing output shape, just to assess the overall size of the data available\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mnew shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_and_valid.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'train_and_valid' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "f0849a55-63b9-4f41-ac3e-37d53d0d09de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importing packages project wide"
   ]
  },
  {
   "cell_type": "code",
   "id": "62bd3c2c-b999-43b1-b6a2-42d7db9727a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T11:08:26.655970Z",
     "start_time": "2025-11-30T11:08:23.300013Z"
    }
   },
   "source": [
    "# Data importing, and integrity checking\n",
    "import os\n",
    "import pandas as pd\n",
    "# for easy Path definitions\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# for visualizing shadowy images\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# optional (I just like the summary output; install if you want with either pip or conda the package \"torchsummary\")\n",
    "from torchsummary import summary"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "8266bef9-3a74-42a1-8641-767d588eca2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Seed setting functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "4da553b7-71be-4df4-98ae-6f1602abfb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T11:08:26.965768Z",
     "start_time": "2025-11-30T11:08:26.952592Z"
    }
   },
   "source": [
    "# setting seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# setting worker seed ids, also for reproducibility (in the DataLoader objects)\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_seed = master_seed + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    torch.manual_seed(worker_seed)\n",
    "\n",
    "\n",
    "master_seed = 42\n",
    "set_seed(master_seed)\n",
    "# defining generator\n",
    "g = torch.Generator()\n",
    "g.manual_seed(master_seed)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2d19f8b4f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "1cbea071-02e4-4043-81c8-4759231e4b7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Path definition\n",
    "\n",
    "I know, we shouldn't need to have this, but we are using 2 systems, with 2 different OS-es, and completely different file management systems\n",
    "\n",
    "So I say, at least for now, we need it"
   ]
  },
  {
   "cell_type": "code",
   "id": "38699962-5114-432f-bea3-5de9e12304b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:45:18.728866Z",
     "start_time": "2025-11-30T12:45:18.720343Z"
    }
   },
   "source": [
    "# Change this string to match the profile key below\n",
    "CURRENT_USER = \"NICO\"  # Options: \"ALEX\", \"NICO\"\n",
    "USE_SMALL_DATA = True\n",
    "\n",
    "\n",
    "# Defining profiles\n",
    "\n",
    "# 'root': The base folder for the project\n",
    "# 'csv_dir': Where CSVs live (relative to root)\n",
    "# 'video_dir': Where the video folders live (relative to root)\n",
    "PROFILES = {\n",
    "    \"ALEX\": {\n",
    "        \"root\": Path(\"/vol/home/s4316061/CV_assignments/3_assign\"),  # common path, from system root, to project folder\n",
    "        \"csv_dir\": \"\",  # Empty string means \"directly in root\", so like: \"CV_assignments/3_assign/jester-v1-validation.csv\" for me\n",
    "        \"video_dir\": \"downloaded_data_small\",\n",
    "        \"cached_images\": \"downloaded_data_small\",\n",
    "        # I added this later, to make the training process faster (it is the folder I use to save the mean images,\n",
    "        # so the script does not calculate the mean every time it wants to load it to the model)\n",
    "    },\n",
    "    \"NICO\": {\n",
    "        \"root\": Path(\"data\"),  # Relative path likely works best, you used just \"data/\" in the shared file, so if it doesn't work, please change as needed\n",
    "        \"csv_dir\": \"labels\",  # so like: \"data/labels\", where labels is a directory\n",
    "        \"video_dir\": \"videos\",\n",
    "        \"cached_images\": \"cache\"  # change carefully: it needs to be in the same parent directory as your directory for the small dataset, and have\n",
    "        # \"cached_images\" as the name. It HAS to match perfectly, otherwise the training will not work\n",
    "    }\n",
    "}\n",
    "\n",
    "# PATH GENERATOR FUNCTION (for all the future instances where we need Paths)\n",
    "def get_project_paths(user_profile, use_small=True):\n",
    "    \"\"\"\n",
    "    Returns (train_annotation, val_annotation, video_root) based on the user profile.\n",
    "    \"\"\"\n",
    "    if user_profile not in PROFILES:\n",
    "        raise ValueError(f\"Profile '{user_profile}' not found in PROFILES dictionary.\")\n",
    "    \n",
    "    config = PROFILES[user_profile]\n",
    "    root = config[\"root\"]\n",
    "    \n",
    "    # defining CONSTANT Filenames (these should be the same for both of us, just locations should be different)\n",
    "    if use_small:\n",
    "        train_csv_name = \"jester-v1-small-train.csv\"\n",
    "        # Matches folder name: \"small-20bn-jester-v1\"\n",
    "        dataset_folder_name = \"small-20bn-jester-v1\"  # should be what the zip file unpacked\n",
    "    else:\n",
    "        train_csv_name = \"jester-v1-train.csv\"\n",
    "        # Assuming full dataset name; adjust if needed\n",
    "        dataset_folder_name = \"20bn-jester-v1\"   # this is guessing, shouldn't be used until we need the full dataset\n",
    "        \n",
    "    val_csv_name = \"jester-v1-validation.csv\"\n",
    "\n",
    "    mean_cache_folder_name = \"mean_cached_images\"\n",
    "    diff_cache_folder_name = \"diff_cached_images\"\n",
    "    rel_diff_cache_folder_name = \"rel_diff_cached_images\"\n",
    "\n",
    "    # Build Full Paths using '/'' operator with logic: Root / Subfolder / Filename (Pathlib magic)\n",
    "    train_csv_path = root / config[\"csv_dir\"] / train_csv_name\n",
    "    val_csv_path   = root / config[\"csv_dir\"] / val_csv_name\n",
    "    \n",
    "    # point to the FOLDER containing the numbered directories\n",
    "    video_root_path = root / config[\"video_dir\"] / dataset_folder_name\n",
    "\n",
    "    # Mean Cache Path: .../downloaded_data_small/mean_cache_images\n",
    "    mean_cache_path = root / config[\"cached_images\"] / mean_cache_folder_name\n",
    "    # Diff Cache Path: .../downloaded_data_small/diff_cache_images\n",
    "    diff_cache_path = root / config[\"cached_images\"] / diff_cache_folder_name\n",
    "    # Relative Diff Cache Path: .../downloaded_data_small/rel_diff_cache_images\n",
    "    rel_diff_cache_path = root / config[\"cached_images\"] / rel_diff_cache_folder_name\n",
    "\n",
    "    return train_csv_path, val_csv_path, video_root_path, mean_cache_path, diff_cache_path, rel_diff_cache_path\n",
    "\n",
    "\n",
    "# to be ran once for the whole project\n",
    "train_annotation, val_annotation, video_root, mean_cache_root, diff_cache_root, rel_diff_cache_root = get_project_paths(CURRENT_USER, USE_SMALL_DATA)\n",
    "\n",
    "# DEBUG CHECK\n",
    "print(f\"User: {CURRENT_USER}\")\n",
    "print(f\"Train CSV:  {train_annotation}\")\n",
    "print(f\"Video Root: {video_root}\")\n",
    "print(f\"Mean cache Root: {mean_cache_root}\")\n",
    "print(f\"Diff cache Root: {diff_cache_root}\")\n",
    "print(f\"Exists?     {train_annotation.exists()} (CSV), {video_root.exists()} (Video Dir), {mean_cache_root.exists()} (mean_cached Dir)\")\n",
    "# .exists is a Pathlib method\n",
    "\n",
    "train_annotation, val_annotation, video_root, mean_cache_root, diff_cache_root, rel_diff_cache_root = str(train_annotation), str(val_annotation), str(video_root), str(mean_cache_root), str(diff_cache_root), str(rel_diff_cache_root)\n",
    "\n",
    "\n",
    "# to be ran once for the whole project\n",
    "train_annotation, val_annotation, video_root, mean_cache_root, diff_cache_root, rel_diff_cache_root = get_project_paths(CURRENT_USER, USE_SMALL_DATA)\n",
    "\n",
    "# DEBUG CHECK \n",
    "print(f\"User: {CURRENT_USER}\")\n",
    "print(f\"Train CSV:  {train_annotation}\")\n",
    "print(f\"Video Root: {video_root}\")\n",
    "print(f\"Mean cache Root: {mean_cache_root}\")\n",
    "print(f\"Diff cache Root: {diff_cache_root}\")\n",
    "print(f\"Exists?     {train_annotation.exists()} (CSV), {video_root.exists()} (Video Dir), {mean_cache_root.exists()} (mean_cached Dir)\")\n",
    "# .exists is a Pathlib method\n",
    "\n",
    "train_annotation, val_annotation, video_root, mean_cache_root, diff_cache_root, rel_diff_cache_root = str(train_annotation), str(val_annotation), str(video_root), str(mean_cache_root), str(diff_cache_root), str(rel_diff_cache_root)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: NICO\n",
      "Train CSV:  data\\labels\\jester-v1-small-train.csv\n",
      "Video Root: data\\videos\\small-20bn-jester-v1\n",
      "Mean cache Root: data\\cache\\mean_cached_images\n",
      "Diff cache Root: data\\cache\\diff_cached_images\n",
      "Exists?     True (CSV), True (Video Dir), True (mean_cached Dir)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "2f22b5b3-2d38-4c56-80f1-340e1df53410",
   "metadata": {},
   "source": [
    "# Single image with mean pixel value (baseline data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c611b46-6c19-4c1d-8b37-443c709a725c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mean pixel value class"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab697b6f-6047-4b56-afd1-df707491408d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:42:31.603699Z",
     "start_time": "2025-11-29T19:42:31.593583Z"
    }
   },
   "source": [
    "class JesterMeanBaselineDataset(Dataset):\n",
    "    def __init__(self, data_root, annotation_file, transform=None,\n",
    "                 text_label_dict=None, trim_percent=0.3, cache_dir=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cache_dir (str): Path to a folder where .pt files will be saved.\n",
    "                             If None, caching is disabled.\n",
    "        \"\"\"\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        # Create cache directory if it's enabled and doesn't exist\n",
    "        if self.cache_dir is not None:\n",
    "            os.makedirs(self.cache_dir, exist_ok=True)\n",
    "            print(f\"Dataset Caching Enabled. Saving .pt files to: {self.cache_dir}\")\n",
    "\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.trim_percent = trim_percent  # effectively trims the images by 2 * trim_percent. This is done to\n",
    "        # keep mostly relevant frames from the image, as usually the first trim_percent frames is the\n",
    "        # subject starring at the camera, motionless, and so are the last trim_percent frames, making\n",
    "        # the output image noisy, or motionless\n",
    "\n",
    "        # load CSV data\n",
    "        df = pd.read_csv(annotation_file, sep=';', header=None, names=['video_id', 'label'])\n",
    "        self.video_ids = df['video_id'].astype(str).tolist()\n",
    "        raw_labels = df['label'].tolist()\n",
    "\n",
    "        # id_to_label_map for future lookup of predictions (so we can see what the model predicts in language. not numbers)\n",
    "        self.id_to_label_map = pd.Series(df.label.values, index=df.video_id).to_dict()\n",
    "\n",
    "        if text_label_dict is not None:\n",
    "            self.class_to_idx = text_label_dict\n",
    "        else:\n",
    "            # creates the gesture: numeric_label map, from the gestures in train. This will be important for Validation later\n",
    "            unique_labels = sorted(list(set(raw_labels)))\n",
    "            self.class_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "        self.labels = [self.class_to_idx[l] for l in raw_labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f\"Attempting to load {idx}\")\n",
    "        video_id = self.video_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # CACHE PATH: if caching is on, check if we already did the work for this video: saves us A LOT of compute\n",
    "        if self.cache_dir:\n",
    "            cache_path = os.path.join(self.cache_dir, f\"{video_id}.pt\")\n",
    "            if os.path.exists(cache_path):\n",
    "                # print(f\"Loading {idx} from cache\")\n",
    "                # FAST PATH: Load tensor directly\n",
    "                mean_image = torch.load(cache_path)\n",
    "                return mean_image, label\n",
    "\n",
    "        # SLOW PATH: Calculate from scratch\n",
    "        video_dir = os.path.join(self.data_root, video_id)\n",
    "\n",
    "        try:\n",
    "            frame_names = sorted([x for x in os.listdir(video_dir) if x.endswith('.jpg')])\n",
    "            # debugging: seeing how many frames there are at the beginning\n",
    "            # print(f\"Video {video_id}: First={frame_names[0]}, Last={frame_names[-1]}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"missed some image\")\n",
    "            return torch.zeros(1), label\n",
    "\n",
    "        total_frames = len(frame_names)\n",
    "\n",
    "        # Image trimming\n",
    "        # calculate how many frames to drop from each side\n",
    "        cut_amount = int(total_frames * self.trim_percent)\n",
    "        # it keeps everything if cut is 0.0 (means there aren't enough images to cut trim_percent*2 from)\n",
    "        if cut_amount > 0:\n",
    "            # revert to keeping only the middle frame if we cut too much (trim_percent >= 0.5)\n",
    "            if (total_frames - (2 * cut_amount)) <= 0:\n",
    "                mid = total_frames // 2\n",
    "                frame_names = [frame_names[mid]]\n",
    "            else:\n",
    "                # trim it up\n",
    "                frame_names = frame_names[cut_amount : -cut_amount]\n",
    "\n",
    "\n",
    "        # self.frames_available = len(frame_names)\n",
    "        # debugging: seeing how many images are left, from how many there were (previous print)\n",
    "        # print(f\"Video {video_id}: First={frame_names[0]}, Last={frame_names[-1]}\")\n",
    "\n",
    "        # Loading and Transforming the remaining frames\n",
    "        tensors = []\n",
    "        for frame_name in frame_names:\n",
    "            img_path = os.path.join(video_dir, frame_name)\n",
    "\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "            # Resize/ToTensor happen here\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            tensors.append(img)\n",
    "\n",
    "        # stack all frames. so  shape (32, 3, H, W)\n",
    "        stacked_video = torch.stack(tensors)\n",
    "        # getting the mean along \"Time\", resulting in a shape of (3, H, W)\n",
    "        mean_image = torch.mean(stacked_video, dim=0)\n",
    "\n",
    "        # CACHE SAVE: saving the result so we never have to calculate it again\n",
    "        if self.cache_dir:\n",
    "            # torch.save(mean_image, cache_path)  # saves a .pt file, which is much fater for torch to load in the CACHE PATH\n",
    "\n",
    "            if not os.path.exists(cache_path):\n",
    "                # Write to a temporary file first\n",
    "                tmp_path = cache_path + \".tmp\"\n",
    "\n",
    "                try:\n",
    "                    # Save to temp file\n",
    "                    torch.save(mean_image, tmp_path)\n",
    "\n",
    "                    # Atomic replace ensures only one worker succeeds\n",
    "                    os.replace(tmp_path, cache_path)\n",
    "\n",
    "                except FileExistsError:\n",
    "                    # Another worker beat us to it. Safe to ignore.\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    # Clean up partial file if something went wrong\n",
    "                    if os.path.exists(tmp_path):\n",
    "                        try:\n",
    "                            os.remove(tmp_path)\n",
    "                        except:\n",
    "                            pass\n",
    "                    print(f\"Cache save error for {video_id}: {e}\")\n",
    "\n",
    "        return mean_image, label"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Absolute Difference class",
   "id": "5817e0a980baf3b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:38:01.546363Z",
     "start_time": "2025-11-30T12:38:01.535458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class JesterDiffBaselineDataset(Dataset):\n",
    "    def __init__(self, data_root, annotation_file, transform=None,\n",
    "                 text_label_dict=None, trim_percent=0.3, cache_dir=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cache_dir (str): Path to a folder where .pt files will be saved.\n",
    "                             If None, caching is disabled.\n",
    "        \"\"\"\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        # Create cache directory if it's enabled and doesn't exist\n",
    "        if self.cache_dir is not None:\n",
    "            os.makedirs(self.cache_dir, exist_ok=True)\n",
    "            print(f\"Dataset Caching Enabled. Saving .pt files to: {self.cache_dir}\")\n",
    "\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.trim_percent = trim_percent  # effectively trims the images by 2 * trim_percent. This is done to\n",
    "        # keep mostly relevant frames from the image, as usually the first trim_percent frames is the\n",
    "        # subject starring at the camera, motionless, and so are the last trim_percent frames, making\n",
    "        # the output image noisy, or motionless\n",
    "\n",
    "        # load CSV data\n",
    "        df = pd.read_csv(annotation_file, sep=';', header=None, names=['video_id', 'label'])\n",
    "        self.video_ids = df['video_id'].astype(str).tolist()\n",
    "        raw_labels = df['label'].tolist()\n",
    "\n",
    "        # id_to_label_map for future lookup of predictions (so we can see what the model predicts in language. not numbers)\n",
    "        self.id_to_label_map = pd.Series(df.label.values, index=df.video_id).to_dict()\n",
    "\n",
    "        if text_label_dict is not None:\n",
    "            self.class_to_idx = text_label_dict\n",
    "        else:\n",
    "            # creates the gesture: numeric_label map, from the gestures in train. This will be important for Validation later\n",
    "            unique_labels = sorted(list(set(raw_labels)))\n",
    "            self.class_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "        self.labels = [self.class_to_idx[l] for l in raw_labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f\"Attempting to load {idx}\")\n",
    "        video_id = self.video_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # CACHE PATH: if caching is on, check if we already did the work for this video: saves us A LOT of compute\n",
    "        if self.cache_dir:\n",
    "            cache_path = os.path.join(self.cache_dir, f\"{video_id}.pt\")\n",
    "            if os.path.exists(cache_path):\n",
    "                # print(f\"Loading {idx} from cache\")\n",
    "                # FAST PATH: Load tensor directly\n",
    "                mean_image = torch.load(cache_path)\n",
    "                return mean_image, label\n",
    "\n",
    "        # SLOW PATH: Calculate from scratch\n",
    "        video_dir = os.path.join(self.data_root, video_id)\n",
    "\n",
    "        try:\n",
    "            frame_names = sorted([x for x in os.listdir(video_dir) if x.endswith('.jpg')])\n",
    "            # debugging: seeing how many frames there are at the beginning\n",
    "            # print(f\"Video {video_id}: First={frame_names[0]}, Last={frame_names[-1]}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"missed some image\")\n",
    "            return torch.zeros(1), label\n",
    "\n",
    "        total_frames = len(frame_names)\n",
    "\n",
    "        first_img_path = os.path.join(video_dir, frame_names[0])\n",
    "        with Image.open(first_img_path) as img:\n",
    "                first_img = img.convert(\"RGB\")\n",
    "        if self.transform:\n",
    "                first_img = self.transform(first_img)\n",
    "\n",
    "        # Image trimming\n",
    "        # calculate how many frames to drop from each side\n",
    "        cut_amount = int(total_frames * self.trim_percent)\n",
    "        # it keeps everything if cut is 0.0 (means there aren't enough images to cut trim_percent*2 from)\n",
    "        if cut_amount > 0:\n",
    "            # revert to keeping only the middle frame if we cut too much (trim_percent >= 0.5)\n",
    "            if (total_frames - (2 * cut_amount)) <= 0:\n",
    "                mid = total_frames // 2\n",
    "                frame_names = [frame_names[mid]]\n",
    "            else:\n",
    "                # trim it up\n",
    "                frame_names = frame_names[cut_amount : -cut_amount]\n",
    "\n",
    "\n",
    "        # self.frames_available = len(frame_names)\n",
    "        # debugging: seeing how many images are left, from how many there were (previous print)\n",
    "        # print(f\"Video {video_id}: First={frame_names[0]}, Last={frame_names[-1]}\")\n",
    "\n",
    "        # Loading and Transforming the remaining frames\n",
    "        tensors = []\n",
    "        for frame_name in frame_names:\n",
    "            img_path = os.path.join(video_dir, frame_name)\n",
    "\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "            # Resize/ToTensor happen here\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            img = torch.abs(img - first_img)\n",
    "\n",
    "            tensors.append(img)\n",
    "\n",
    "        # stack all frames. so  shape (32, 3, H, W)\n",
    "        stacked_video = torch.stack(tensors)\n",
    "        # getting the mean along \"Time\", resulting in a shape of (3, H, W)\n",
    "        mean_image = torch.mean(stacked_video, dim=0)\n",
    "\n",
    "        # CACHE SAVE: saving the result so we never have to calculate it again\n",
    "        if self.cache_dir:\n",
    "            # torch.save(mean_image, cache_path)  # saves a .pt file, which is much fater for torch to load in the CACHE PATH\n",
    "\n",
    "            if not os.path.exists(cache_path):\n",
    "                # Write to a temporary file first\n",
    "                tmp_path = cache_path + \".tmp\"\n",
    "\n",
    "                try:\n",
    "                    # Save to temp file\n",
    "                    torch.save(mean_image, tmp_path)\n",
    "\n",
    "                    # Atomic replace ensures only one worker succeeds\n",
    "                    os.replace(tmp_path, cache_path)\n",
    "\n",
    "                except FileExistsError:\n",
    "                    # Another worker beat us to it. Safe to ignore.\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    # Clean up partial file if something went wrong\n",
    "                    if os.path.exists(tmp_path):\n",
    "                        try:\n",
    "                            os.remove(tmp_path)\n",
    "                        except:\n",
    "                            pass\n",
    "                    print(f\"Cache save error for {video_id}: {e}\")\n",
    "\n",
    "        return mean_image, label"
   ],
   "id": "f9e7d03a6de52b31",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Relative Difference Class",
   "id": "bb7a3da589c51c87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:53:32.471647Z",
     "start_time": "2025-11-30T12:53:32.461185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class JesterRelDiffBaselineDataset(Dataset):\n",
    "    def __init__(self, data_root, annotation_file, transform=None,\n",
    "                 text_label_dict=None, trim_percent=0.3, cache_dir=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cache_dir (str): Path to a folder where .pt files will be saved.\n",
    "                             If None, caching is disabled.\n",
    "        \"\"\"\n",
    "        self.cache_dir = cache_dir\n",
    "\n",
    "        # Create cache directory if it's enabled and doesn't exist\n",
    "        if self.cache_dir is not None:\n",
    "            os.makedirs(self.cache_dir, exist_ok=True)\n",
    "            print(f\"Dataset Caching Enabled. Saving .pt files to: {self.cache_dir}\")\n",
    "\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.trim_percent = trim_percent  # effectively trims the images by 2 * trim_percent. This is done to\n",
    "        # keep mostly relevant frames from the image, as usually the first trim_percent frames is the\n",
    "        # subject starring at the camera, motionless, and so are the last trim_percent frames, making\n",
    "        # the output image noisy, or motionless\n",
    "\n",
    "        # load CSV data\n",
    "        df = pd.read_csv(annotation_file, sep=';', header=None, names=['video_id', 'label'])\n",
    "        self.video_ids = df['video_id'].astype(str).tolist()\n",
    "        raw_labels = df['label'].tolist()\n",
    "\n",
    "        # id_to_label_map for future lookup of predictions (so we can see what the model predicts in language. not numbers)\n",
    "        self.id_to_label_map = pd.Series(df.label.values, index=df.video_id).to_dict()\n",
    "\n",
    "        if text_label_dict is not None:\n",
    "            self.class_to_idx = text_label_dict\n",
    "        else:\n",
    "            # creates the gesture: numeric_label map, from the gestures in train. This will be important for Validation later\n",
    "            unique_labels = sorted(list(set(raw_labels)))\n",
    "            self.class_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "        self.labels = [self.class_to_idx[l] for l in raw_labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f\"Attempting to load {idx}\")\n",
    "        video_id = self.video_ids[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # CACHE PATH: if caching is on, check if we already did the work for this video: saves us A LOT of compute\n",
    "        if self.cache_dir:\n",
    "            cache_path = os.path.join(self.cache_dir, f\"{video_id}.pt\")\n",
    "            if os.path.exists(cache_path):\n",
    "                # print(f\"Loading {idx} from cache\")\n",
    "                # FAST PATH: Load tensor directly\n",
    "                mean_image = torch.load(cache_path)\n",
    "                return mean_image, label\n",
    "\n",
    "        # SLOW PATH: Calculate from scratch\n",
    "        video_dir = os.path.join(self.data_root, video_id)\n",
    "\n",
    "        try:\n",
    "            frame_names = sorted([x for x in os.listdir(video_dir) if x.endswith('.jpg')])\n",
    "            # debugging: seeing how many frames there are at the beginning\n",
    "            # print(f\"Video {video_id}: First={frame_names[0]}, Last={frame_names[-1]}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"missed some image\")\n",
    "            return torch.zeros(1), label\n",
    "\n",
    "        total_frames = len(frame_names)\n",
    "\n",
    "        # Image trimming\n",
    "        # calculate how many frames to drop from each side\n",
    "        cut_amount = int(total_frames * self.trim_percent)\n",
    "        # it keeps everything if cut is 0.0 (means there aren't enough images to cut trim_percent*2 from)\n",
    "        if cut_amount > 0:\n",
    "            # revert to keeping only the middle frame if we cut too much (trim_percent >= 0.5)\n",
    "            if (total_frames - (2 * cut_amount)) <= 0:\n",
    "                mid = total_frames // 2\n",
    "                frame_names = [frame_names[mid]]\n",
    "            else:\n",
    "                # trim it up\n",
    "                frame_names = frame_names[cut_amount : -cut_amount]\n",
    "\n",
    "\n",
    "        # self.frames_available = len(frame_names)\n",
    "        # debugging: seeing how many images are left, from how many there were (previous print)\n",
    "        # print(f\"Video {video_id}: First={frame_names[0]}, Last={frame_names[-1]}\")\n",
    "\n",
    "        img_path = os.path.join(video_dir, frame_names[0])\n",
    "\n",
    "        with Image.open(img_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "\n",
    "        # Resize/ToTensor happen here\n",
    "        if self.transform:\n",
    "            previous_img = self.transform(img)\n",
    "        # Loading and Transforming the remaining frames\n",
    "        tensors = []\n",
    "        for frame_name in frame_names[1:]:\n",
    "            img_path = os.path.join(video_dir, frame_name)\n",
    "\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "\n",
    "            # Resize/ToTensor happen here\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            subtracted_img = torch.abs(img - previous_img)\n",
    "\n",
    "            tensors.append(subtracted_img)\n",
    "\n",
    "            previous_img = img\n",
    "\n",
    "        # stack all frames. so  shape (32, 3, H, W)\n",
    "        stacked_video = torch.stack(tensors)\n",
    "        # getting the mean along \"Time\", resulting in a shape of (3, H, W)\n",
    "        mean_image = torch.mean(stacked_video, dim=0)\n",
    "\n",
    "        # CACHE SAVE: saving the result so we never have to calculate it again\n",
    "        if self.cache_dir:\n",
    "            # torch.save(mean_image, cache_path)  # saves a .pt file, which is much fater for torch to load in the CACHE PATH\n",
    "\n",
    "            if not os.path.exists(cache_path):\n",
    "                # Write to a temporary file first\n",
    "                tmp_path = cache_path + \".tmp\"\n",
    "\n",
    "                try:\n",
    "                    # Save to temp file\n",
    "                    torch.save(mean_image, tmp_path)\n",
    "\n",
    "                    # Atomic replace ensures only one worker succeeds\n",
    "                    os.replace(tmp_path, cache_path)\n",
    "\n",
    "                except FileExistsError:\n",
    "                    # Another worker beat us to it. Safe to ignore.\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    # Clean up partial file if something went wrong\n",
    "                    if os.path.exists(tmp_path):\n",
    "                        try:\n",
    "                            os.remove(tmp_path)\n",
    "                        except:\n",
    "                            pass\n",
    "                    print(f\"Cache save error for {video_id}: {e}\")\n",
    "\n",
    "        return mean_image, label"
   ],
   "id": "603ddda799c9ed1a",
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "8cd8f2a3-e77c-4274-b6af-feb4ffdd073f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check integrity of data-loading process\n",
    "\n",
    "Function is called at the end of the cell after it. If errors are returned, the Loader most likely can't reach the video folders\n",
    "\n",
    "Update path parameters to the right ones in the \"Data Path definition\" cell"
   ]
  },
  {
   "cell_type": "code",
   "id": "9934cdd6-b244-44e2-8c27-3b6d79041109",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:46:06.586849Z",
     "start_time": "2025-11-30T12:46:06.580492Z"
    }
   },
   "source": [
    "def check_data_availability(csv_path, video_root_path):\n",
    "    \"\"\"\n",
    "    Verifies that the CSV exists and that the first 5 videos \n",
    "    listed in it can be found in the video_root_path.\n",
    "    \"\"\"\n",
    "    print(f\"--- Sanity check ---\")\n",
    "    print(f\"1. Checking CSV:   {csv_path}\")\n",
    "    print(f\"2. Checking Videos: {video_root_path}\")\n",
    "    print(f\"------------------------\\n\")\n",
    "\n",
    "    # TEST 1: Check CSV Existence\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"CRITICAL FAILURE: CSV file not found!\")\n",
    "        print(f\"Path checked: {csv_path}\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"--- CSV found. ---\")\n",
    "\n",
    "    # TEST 2: Check video_dir content (First 5 videos)\n",
    "    try:\n",
    "        # another sanity check, just for safety\n",
    "        df = pd.read_csv(csv_path, sep=';', header=None, names=['video_id', 'label'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"CSV readable. Checking first 5 entries against video root...\")\n",
    "    \n",
    "    failures = 0\n",
    "    # Check the first 5 rows\n",
    "    for idx, row in df.head(5).iterrows():\n",
    "        video_id = str(row['video_id'])\n",
    "\n",
    "        target_folder = os.path.join(video_root_path, video_id)\n",
    "        \n",
    "        # Check A: Folder exists?\n",
    "        if not os.path.exists(target_folder):\n",
    "            print(f\"--- MISSING FOLDER: {target_folder} ---\")\n",
    "            failures += 1\n",
    "            continue \n",
    "            \n",
    "        # Check B: Contains images?\n",
    "        images = [x for x in os.listdir(target_folder) if x.endswith('.jpg')]\n",
    "        if len(images) == 0:\n",
    "            print(f\"--- EMPTY FOLDER: {target_folder} exists but has 0 images. ---\")\n",
    "            failures += 1\n",
    "        else:\n",
    "            print(f\"--- Found Video {video_id} ({len(images)} frames) ---\")\n",
    "\n",
    "    print(f\"\\n------------------------\")\n",
    "    if failures == 0:\n",
    "        print(\"SUCCESS: File system structure matches the configuration.\")\n",
    "        print(\"Proceed with training.\")\n",
    "    else:\n",
    "        print(f\"FAILURE: {failures}/5 checks failed.\")\n",
    "        print(\"Your paths are configured, but the OS cannot find the specific folders.\")\n",
    "        print(\"Check that 'video_root' points to the folder CONTAINING the numbered directories.\")"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "872328f4-15b0-44be-9334-df15d79e9d97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Instantiating"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Mean class",
   "id": "d82a51c83e3b8705"
  },
  {
   "cell_type": "code",
   "id": "8dd93cc5-13d1-4aaa-9cee-82ca41589cbd",
   "metadata": {},
   "source": [
    "trim_percent = 0.3  # found empirically to yield the best outputs (clearest shadows and images)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 150)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "baseline_data_train = JesterMeanBaselineDataset(\n",
    "    data_root=video_root,\n",
    "    annotation_file=train_annotation,\n",
    "    transform=transform,\n",
    "    trim_percent=trim_percent,\n",
    "    cache_dir=mean_cache_root\n",
    ")\n",
    "\n",
    "# label map learned (generated) from the train videos: e.g. \"Stop sign\" is 1, and so on\n",
    "label_map = baseline_data_train.class_to_idx\n",
    "\n",
    "baseline_data_valid = JesterMeanBaselineDataset(\n",
    "    data_root=video_root,\n",
    "    annotation_file=val_annotation,\n",
    "    transform=transform,\n",
    "    text_label_dict=label_map,  # so the Validation loader does not generate new ones and turn everything on its head\n",
    "    trim_percent=trim_percent,\n",
    "    cache_dir=mean_cache_root\n",
    ")\n",
    "\n",
    "# if train_annotation, then val_annotation works too. This has to return SUCCESS, otherwise the class cannot access the data locations\n",
    "check_data_availability(train_annotation, video_root)\n",
    "\n",
    "# testing 1 item to see trim effectiveness\n",
    "# print(baseline_data_valid[8])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Absolute difference class",
   "id": "7480a328e2819bbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:38:10.752128Z",
     "start_time": "2025-11-30T12:38:10.698852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trim_percent = 0.3  # found empirically to yield the best outputs (clearest shadows and images)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 150)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "baseline_data_train = JesterDiffBaselineDataset(\n",
    "    data_root=video_root,\n",
    "    annotation_file=train_annotation,\n",
    "    transform=transform,\n",
    "    trim_percent=trim_percent,\n",
    "    cache_dir=diff_cache_root\n",
    ")\n",
    "\n",
    "# label map learned (generated) from the train videos: e.g. \"Stop sign\" is 1, and so on\n",
    "label_map = baseline_data_train.class_to_idx\n",
    "\n",
    "baseline_data_valid = JesterDiffBaselineDataset(\n",
    "    data_root=video_root,\n",
    "    annotation_file=val_annotation,\n",
    "    transform=transform,\n",
    "    text_label_dict=label_map,  # so the Validation loader does not generate new ones and turn everything on its head\n",
    "    trim_percent=trim_percent,\n",
    "    cache_dir=diff_cache_root\n",
    ")\n",
    "\n",
    "# if train_annotation, then val_annotation works too. This has to return SUCCESS, otherwise the class cannot access the data locations\n",
    "check_data_availability(train_annotation, video_root)\n",
    "\n",
    "# testing 1 item to see trim effectiveness\n",
    "# print(baseline_data_valid[8])"
   ],
   "id": "71cbccb5615a3517",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Caching Enabled. Saving .pt files to: data\\cache\\diff_cached_images\n",
      "Dataset Caching Enabled. Saving .pt files to: data\\cache\\diff_cached_images\n",
      "--- Sanity check ---\n",
      "1. Checking CSV:   data\\labels\\jester-v1-small-train.csv\n",
      "2. Checking Videos: data\\videos\\small-20bn-jester-v1\n",
      "------------------------\n",
      "\n",
      "--- CSV found. ---\n",
      "CSV readable. Checking first 5 entries against video root...\n",
      "--- Found Video 105128 (36 frames) ---\n",
      "--- Found Video 21610 (33 frames) ---\n",
      "--- Found Video 138719 (35 frames) ---\n",
      "--- Found Video 43350 (33 frames) ---\n",
      "--- Found Video 28142 (35 frames) ---\n",
      "\n",
      "------------------------\n",
      "SUCCESS: File system structure matches the configuration.\n",
      "Proceed with training.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Relative difference class",
   "id": "c5c63414c5d736e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:53:38.949004Z",
     "start_time": "2025-11-30T12:53:38.897751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trim_percent = 0.3  # found empirically to yield the best outputs (clearest shadows and images)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 150)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "baseline_data_train = JesterRelDiffBaselineDataset(\n",
    "    data_root=video_root,\n",
    "    annotation_file=train_annotation,\n",
    "    transform=transform,\n",
    "    trim_percent=trim_percent,\n",
    "    cache_dir=rel_diff_cache_root\n",
    ")\n",
    "\n",
    "# label map learned (generated) from the train videos: e.g. \"Stop sign\" is 1, and so on\n",
    "label_map = baseline_data_train.class_to_idx\n",
    "\n",
    "baseline_data_valid = JesterRelDiffBaselineDataset(\n",
    "    data_root=video_root,\n",
    "    annotation_file=val_annotation,\n",
    "    transform=transform,\n",
    "    text_label_dict=label_map,  # so the Validation loader does not generate new ones and turn everything on its head\n",
    "    trim_percent=trim_percent,\n",
    "    cache_dir=rel_diff_cache_root\n",
    ")\n",
    "\n",
    "# if train_annotation, then val_annotation works too. This has to return SUCCESS, otherwise the class cannot access the data locations\n",
    "check_data_availability(train_annotation, video_root)\n",
    "\n",
    "# testing 1 item to see trim effectiveness\n",
    "# print(baseline_data_valid[8])"
   ],
   "id": "7c67ff1d2362aba9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Caching Enabled. Saving .pt files to: data\\cache\\rel_diff_cached_images\n",
      "Dataset Caching Enabled. Saving .pt files to: data\\cache\\rel_diff_cached_images\n",
      "--- Sanity check ---\n",
      "1. Checking CSV:   data\\labels\\jester-v1-small-train.csv\n",
      "2. Checking Videos: data\\videos\\small-20bn-jester-v1\n",
      "------------------------\n",
      "\n",
      "--- CSV found. ---\n",
      "CSV readable. Checking first 5 entries against video root...\n",
      "--- Found Video 105128 (36 frames) ---\n",
      "--- Found Video 21610 (33 frames) ---\n",
      "--- Found Video 138719 (35 frames) ---\n",
      "--- Found Video 43350 (33 frames) ---\n",
      "--- Found Video 28142 (35 frames) ---\n",
      "\n",
      "------------------------\n",
      "SUCCESS: File system structure matches the configuration.\n",
      "Proceed with training.\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "ed090486-f16f-49b0-b45a-bcdfdb2ff948",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Visually testing the class"
   ]
  },
  {
   "cell_type": "code",
   "id": "595bda9b-a357-456b-be45-b50612857b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T12:53:53.294946Z",
     "start_time": "2025-11-30T12:53:53.229030Z"
    }
   },
   "source": [
    "def show_random_baseline_image(dataset):\n",
    "    \"\"\"\n",
    "    Picks a random sample from the dataset, converts the tensor back to a \n",
    "    viewable image, and displays it with its label.\n",
    "    \"\"\"\n",
    "    idx = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "    img_tensor, label_idx = dataset[idx]\n",
    "    \n",
    "    # Matplotlib expects images in format (Height, Width, Channels)\n",
    "    # so we permute dimensions: (3, H, W) -> (H, W, 3)\n",
    "    img_view = img_tensor.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # We invert the class_to_idx dictionary to get the text back\n",
    "    class_to_idx = dataset.class_to_idx\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    label_text = idx_to_class.get(label_idx, \"Unknown\")\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img_view)\n",
    "    plt.title(f\"Label: {label_text} (ID: {label_idx})\\n'Shadowy' Mean Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_random_baseline_image(baseline_data_valid)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "id": "a4599a71-fedc-4a25-87bd-36c95a7fba5e",
   "metadata": {},
   "source": [
    "If the function returns an input_dim error message, check the \"root\" and \"personal_path\" variables in the Data Loading process (the Class instance call). It falls into the \"FileNotFound\" exception of the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92878a3-062f-4fca-a223-cbdd3064d3c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model: my VGG, as I know well how that works (inside and out)"
   ]
  },
  {
   "cell_type": "code",
   "id": "09afa68e-d32e-4779-abc7-31be76d67913",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:42:33.745826Z",
     "start_time": "2025-11-29T19:42:33.736893Z"
    }
   },
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, num_classes=27):\n",
    "        super().__init__()\n",
    "        \n",
    "        bias = True\n",
    "        \n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=bias),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2,2)) # to halve the image\n",
    "        )\n",
    "\n",
    "        final_out_channels = 256\n",
    "        \n",
    "        self.layer1 = self.make_VGG_layers(in_channels=64, out_channels=128, stride=1, bias=False)\n",
    "        self.layer2 = self.make_VGG_layers(in_channels=128, out_channels=128, stride=1, bias=False)\n",
    "        # self.layer3 = self.make_VGG_layers(in_channels=128, out_channels=128, stride=1, bias=False)\n",
    "        self.layer4 = self.make_VGG_layers(in_channels=128, out_channels=256, stride=1, bias=False)\n",
    "        self.layer5 = self.make_VGG_layers(in_channels=256, out_channels=final_out_channels, stride=1, bias=False, use_pooling=False)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(final_out_channels, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def make_VGG_layers(self, in_channels, out_channels, stride, bias, use_pooling=True):\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if use_pooling:\n",
    "            layers.append(\n",
    "                nn.MaxPool2d((2,2))  # halve the final\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    # weights initialization for reproducibility\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:  # if bias exists, put it at 0\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x, return_intermediate=False):\n",
    "        x = self.initial_conv(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1)\n",
    "        \n",
    "        return self.head(x)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "779b15db-0f59-4448-8bbd-5d8d8bd0f2c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inspecting architecture with summary"
   ]
  },
  {
   "cell_type": "code",
   "id": "10809e0a-3eaf-43b0-b64d-85ecdb19efd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:42:34.986999Z",
     "start_time": "2025-11-29T19:42:34.574984Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# model = MyConv().to(device)\n",
    "model = TinyVGG(num_classes=27).to(device)\n",
    "\n",
    "summary(model, input_size=(3, 100, 150))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 150]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 100, 150]             128\n",
      "              ReLU-3         [-1, 64, 100, 150]               0\n",
      "            Conv2d-4         [-1, 64, 100, 150]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 100, 150]             128\n",
      "              ReLU-6         [-1, 64, 100, 150]               0\n",
      "         MaxPool2d-7           [-1, 64, 50, 75]               0\n",
      "            Conv2d-8          [-1, 128, 50, 75]          73,728\n",
      "       BatchNorm2d-9          [-1, 128, 50, 75]             256\n",
      "             ReLU-10          [-1, 128, 50, 75]               0\n",
      "           Conv2d-11          [-1, 128, 50, 75]         147,456\n",
      "      BatchNorm2d-12          [-1, 128, 50, 75]             256\n",
      "             ReLU-13          [-1, 128, 50, 75]               0\n",
      "        MaxPool2d-14          [-1, 128, 25, 37]               0\n",
      "           Conv2d-15          [-1, 128, 25, 37]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 25, 37]             256\n",
      "             ReLU-17          [-1, 128, 25, 37]               0\n",
      "           Conv2d-18          [-1, 128, 25, 37]         147,456\n",
      "      BatchNorm2d-19          [-1, 128, 25, 37]             256\n",
      "             ReLU-20          [-1, 128, 25, 37]               0\n",
      "        MaxPool2d-21          [-1, 128, 12, 18]               0\n",
      "           Conv2d-22          [-1, 256, 12, 18]         294,912\n",
      "      BatchNorm2d-23          [-1, 256, 12, 18]             512\n",
      "             ReLU-24          [-1, 256, 12, 18]               0\n",
      "           Conv2d-25          [-1, 256, 12, 18]         589,824\n",
      "      BatchNorm2d-26          [-1, 256, 12, 18]             512\n",
      "             ReLU-27          [-1, 256, 12, 18]               0\n",
      "        MaxPool2d-28            [-1, 256, 6, 9]               0\n",
      "           Conv2d-29            [-1, 256, 6, 9]         589,824\n",
      "      BatchNorm2d-30            [-1, 256, 6, 9]             512\n",
      "             ReLU-31            [-1, 256, 6, 9]               0\n",
      "           Conv2d-32            [-1, 256, 6, 9]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 6, 9]             512\n",
      "             ReLU-34            [-1, 256, 6, 9]               0\n",
      "AdaptiveAvgPool2d-35            [-1, 256, 1, 1]               0\n",
      "           Linear-36                  [-1, 128]          32,896\n",
      "             ReLU-37                  [-1, 128]               0\n",
      "          Dropout-38                  [-1, 128]               0\n",
      "           Linear-39                   [-1, 27]           3,483\n",
      "================================================================\n",
      "Total params: 2,658,907\n",
      "Trainable params: 2,658,907\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.17\n",
      "Forward/backward pass size (MB): 77.56\n",
      "Params size (MB): 10.14\n",
      "Estimated Total Size (MB): 87.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "f7a97d5f-17f5-40a7-9344-dadc4b686221",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train and Eval functions (mine, sorry but I've stayed here way too long, and I know how these work far better)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b28efca-6a84-4445-ac67-562351d58023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:42:36.256584Z",
     "start_time": "2025-11-29T19:42:36.248807Z"
    }
   },
   "source": [
    "def calculate_test_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # pre-allocate tensors on GPU to avoid repeated transfers\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader):\n",
    "            # data passed to gpu every batch\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            \n",
    "            # calculating accuracy on GPU\n",
    "            correct += (preds == labels).sum()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    # moving final scalar to CPU\n",
    "    accuracy = (correct.float() / total) * 100\n",
    "    return accuracy.item()\n",
    "\n",
    "def train_model(model, train_loader, test_loader, device, num_epochs=20, lr=0.001):\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # use torch.amp for mixed precision training\n",
    "    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # training loop with progress bar\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\"):\n",
    "            # move to gpu once per batch\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # zero gradients\n",
    "            optimizer.zero_grad(set_to_none=True)  # More efficient than zeroing\n",
    "            \n",
    "            # mixed precision forward pass\n",
    "            if scaler:\n",
    "                with torch.amp.autocast(device_type='cuda'):\n",
    "                    outputs = model(images)\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                # Mixed precision backward pass and optimization\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                # standard precision, just in case\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        scheduler.step()\n",
    "        # get the epoch numbers\n",
    "        avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # evaluate on the validation set\n",
    "        val_accuracy = calculate_test_accuracy(model, test_loader, device)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch:02d}: Train loss: {avg_train_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return train_losses, val_accuracies"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "01df0d47-6267-4043-a859-1caac73f21dd",
   "metadata": {},
   "source": [
    "## Data Loading and Training"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:43:59.854553300Z",
     "start_time": "2025-11-29T19:42:40.004912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "print(device)\n",
    "if device == \"cpu\":\n",
    "    num_workers = min(12, os.cpu_count() or 2)  # dynamic core loading; swap the hard limit (12) depending on the amount of ram available (<16)\n",
    "else:\n",
    "    num_workers = 4 # I have this temporarily I will just set it to 4 for me\n",
    "# some computers can handle 12 core usage, but (with the assumption that we're calculating for video processing) we might run into OOM\n",
    "# \"Out of Memory\" errors on the RAM side, not the VRAM side. Note that this is foe Data Loading only! inspect machine_limit.py file for more info\n",
    "epochs = 20\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    baseline_data_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    generator=g,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    baseline_data_valid,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    img_view = images[0].permute(1, 2, 0).numpy()\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img_view)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "model = TinyVGG(num_classes=27).to(device)"
   ],
   "id": "fc6be24c5450578b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83755daf-f871-4a09-a435-d36a91242a91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:19:30.657495Z",
     "start_time": "2025-11-29T19:19:00.179746Z"
    }
   },
   "source": [
    "\n",
    "train_losses, test_accuracies = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=val_loader,\n",
    "    device=device,\n",
    "    num_epochs=epochs,\n",
    "    lr=0.001\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/371 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
